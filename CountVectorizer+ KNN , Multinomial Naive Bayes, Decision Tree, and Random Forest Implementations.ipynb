{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "plain-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fiscal-yemen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id keyword location  \\\n",
      "0         1     NaN      NaN   \n",
      "1         4     NaN      NaN   \n",
      "2         5     NaN      NaN   \n",
      "3         6     NaN      NaN   \n",
      "4         7     NaN      NaN   \n",
      "...     ...     ...      ...   \n",
      "7608  10869     NaN      NaN   \n",
      "7609  10870     NaN      NaN   \n",
      "7610  10871     NaN      NaN   \n",
      "7611  10872     NaN      NaN   \n",
      "7612  10873     NaN      NaN   \n",
      "\n",
      "                                                   text  target  \n",
      "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
      "1                Forest fire near La Ronge Sask. Canada       1  \n",
      "2     All residents asked to 'shelter in place' are ...       1  \n",
      "3     13,000 people receive #wildfires evacuation or...       1  \n",
      "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
      "...                                                 ...     ...  \n",
      "7608  Two giant cranes holding a bridge collapse int...       1  \n",
      "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
      "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
      "7611  Police investigating after an e-bike collided ...       1  \n",
      "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
      "\n",
      "[7613 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "streaming-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "innovative-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how does\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'd've\": \"i would have\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'll've\": \"i will have\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so is\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\" u \": \" you \",\n",
    "\" ur \": \" your \",\n",
    "\" n \": \" and \"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "comic-buffalo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_clean_text(x):\n",
    "    if type(x) is str:\n",
    "        x = x.lower()\n",
    "        for key in contractions:\n",
    "            value = contractions[key]\n",
    "            x = x.replace(key, value)\n",
    "            #regex to remove emails and replace with space\n",
    "            x = re.sub(r'([a-zA-Z0-9+._-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z0-9_-]+)', '', x) \n",
    "              #regex to remove URLs\n",
    "            x = re.sub(r'(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '', x)\n",
    "            #removing html tags\n",
    "            #removing punctuation and numbers\n",
    "            x = re.sub(r'[^a-zA-Z]', ' ', x)\n",
    "            \n",
    "            clean = re.compile('<.*?>')\n",
    "            x= re.sub(clean, '', x)\n",
    "           \n",
    "            return x\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "every-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: get_clean_text(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "informal-cache",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       our deeds are the reason of this  earthquake m...\n",
       "1                  forest fire near la ronge sask  canada\n",
       "2       all residents asked to  shelter in place  are ...\n",
       "3              people receive  wildfires evacuation or...\n",
       "4       just got sent this photo from ruby  alaska as ...\n",
       "                              ...                        \n",
       "7608    two giant cranes holding a bridge collapse int...\n",
       "7609     aria ahrary  thetawniest the out of control w...\n",
       "7610          m            utc   km s of volcano hawaii  \n",
       "7611    police investigating after an e bike collided ...\n",
       "7612    the latest  more homes razed by northern calif...\n",
       "Name: text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "current-documentary",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DeLL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "<ipython-input-9-e137c2ebcbb9>:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text'] = df['text'].str.replace(pat, '')\n",
      "<ipython-input-9-e137c2ebcbb9>:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text'] = df['text'].str.replace(r'\\s+', ' ')\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "pat = r'\\b(?:{})\\b'.format('|'.join(stop))\n",
    "df['text'] = df['text'].str.replace(pat, '')\n",
    "df['text'] = df['text'].str.replace(r'\\s+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sacred-accommodation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-41c18e65cc79>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text'] = df['text'].str.replace('[^\\w\\s]','') #to remove punctuation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df['text'] = df['text'].str.replace('[^\\w\\s]','') #to remove punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "passing-twelve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7613x16052 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 67053 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = df['text']\n",
    "y = df['target']\n",
    "\n",
    "X = vectorizer.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "vital-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "transformer = MaxAbsScaler().fit(X)\n",
    "X_scaled=transformer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "joint-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "divine-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "endangered-fellowship",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=101)\n",
    "knn.fit(X_train, y_train)\n",
    "y_predict = knn.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "looking-greene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5817465528562049\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', metrics.accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "incoming-parent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[886   0]\n",
      " [637   0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "closing-disney",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.74       886\n",
      "           1       0.00      0.00      0.00       637\n",
      "\n",
      "    accuracy                           0.58      1523\n",
      "   macro avg       0.29      0.50      0.37      1523\n",
      "weighted avg       0.34      0.58      0.43      1523\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DeLL\\anacondanew\\envs\\TensorFlow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DeLL\\anacondanew\\envs\\TensorFlow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\DeLL\\anacondanew\\envs\\TensorFlow\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "grave-rocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "married-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = naive_bayes.MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "valid-progress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[749 137]\n",
      " [169 468]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "static-texas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83       886\n",
      "           1       0.77      0.73      0.75       637\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.79      0.79      0.79      1523\n",
      "weighted avg       0.80      0.80      0.80      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "coastal-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "# Create Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier(criterion='entropy',splitter='random')\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "detected-commonwealth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7636244254760342\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adaptive-honolulu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[744 142]\n",
      " [218 419]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "through-barrel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.84      0.81       886\n",
      "           1       0.75      0.66      0.70       637\n",
      "\n",
      "    accuracy                           0.76      1523\n",
      "   macro avg       0.76      0.75      0.75      1523\n",
      "weighted avg       0.76      0.76      0.76      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "representative-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# creating a RF classifier\n",
    "clf = RandomForestClassifier(n_estimators = 100)  \n",
    "  \n",
    "# Training the model on the training dataset\n",
    "# fit function is used to train the model using the training sets as parameters\n",
    "clf.fit(X_train, y_train)\n",
    "  \n",
    "# performing predictions on the test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "  \n",
    "# metrics are used to find accuracy or error\n",
    "from sklearn import metrics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "civilian-oxygen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF THE RANDOM FOREST MODEL:  0.804333552199606\n"
     ]
    }
   ],
   "source": [
    "print(\"ACCURACY OF THE RANDOM FOREST MODEL: \", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "through-nerve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[817  69]\n",
      " [229 408]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "offshore-listening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.92      0.85       886\n",
      "           1       0.86      0.64      0.73       637\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.82      0.78      0.79      1523\n",
      "weighted avg       0.81      0.80      0.80      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-apache",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
